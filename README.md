# RLHF-papers
![Awesome](https://awesome.re/badge.svg)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://github.com/shenggan/awesome-distributed-ml/pulls)

Collecting RLHF papers.
## Language 
### OpenAI
- [Fine-Tuning Language Models from Human Preferences](https://arxiv.org/abs/1909.08593)
- [Learning to summarize from human feedback](https://arxiv.org/abs/2009.01325)
- [Improving language model behavior by training on a curated dataset](https://cdn.openai.com/palms.pdf)
- [webgpt](https://arxiv.org/abs/2112.09332)
- [Instruct GPT](https://arxiv.org/abs/2203.02155)
- [Scaling Laws for Reward Model Overoptimization](https://arxiv.org/abs/2210.10760)

### Anthropic

### DeepMind

### Academia
- [Learning to Summarise Without References](https://arxiv.org/abs/1909.01214)
- [A survey of RL informed by natural language](https://arxiv.org/abs/1906.03926)
## Visual

## Theory
- [Preference Transformer](https://arxiv.org/abs/2303.00957)
- 
